{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sparkSession.read.parquet(\"/data/sample264\")\n",
    "meta = sparkSession.read.parquet(\"/data/meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+----------+\n",
      "|userId|trackId|artistId| timestamp|\n",
      "+------+-------+--------+----------+\n",
      "| 13065| 944906|  978428|1501588527|\n",
      "|101897| 799685|  989262|1501555608|\n",
      "|215049| 871513|  988199|1501604269|\n",
      "|309769| 857670|  987809|1501540265|\n",
      "|397833| 903510|  994595|1501597615|\n",
      "|501769| 818149|  994975|1501577955|\n",
      "|601353| 958990|  973098|1501602467|\n",
      "|710921| 916226|  972031|1501611582|\n",
      "|  6743| 801006|  994339|1501584964|\n",
      "|152407| 913509|  994334|1501571055|\n",
      "+------+-------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+-------+\n",
      "|  type|                Name|              Artist|     Id|\n",
      "+------+--------------------+--------------------+-------+\n",
      "| track|               Smile| Artist: Josh Groban|1223851|\n",
      "| track|Chuni Ashkharhe Q...|Artist: Razmik Amyan|1215486|\n",
      "| track|           Dark City|Artist: Machinae ...|1296462|\n",
      "| track|       Not Sensitive|        Artist: Moby|1249694|\n",
      "|artist|Artist: Carlos Pu...|Artist: Carlos Pu...|1352221|\n",
      "| track|Thiz Gangsta Chit...|Artist: Tha Dogg ...|1217194|\n",
      "| track|            Ruffneck|    Artist: Skrillex|1245681|\n",
      "| track|              Incerc|       Artist: Spike|1193283|\n",
      "|artist|Artist: Wallenber...|Artist: Wallenber...|1333444|\n",
      "| track|               remix|    Artist: Flo Rida|1246378|\n",
      "+------+--------------------+--------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-72c04ca38c89>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-72c04ca38c89>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    +------+-------+-----+---------+--------------------+\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number, sum\n",
    "\n",
    "#df = userTrack(userId, trackId, count); key1 = \"userId\"; key2 = \"trackId\"; field = \"count\"; n = 1000\n",
    "def norm(df, key1, key2, field, n): \n",
    "    \n",
    "    #Form window partitioned by userId ordered by count. \n",
    "    #key1 = \"userId\"; field = \"count\"\n",
    "    window = Window.partitionBy(key1).orderBy(col(field).desc())\n",
    "    \n",
    "    #Numerate most popular tracks for each userId. Select top 1000 for each user\n",
    "    topsDF = df.withColumn(\"row_number\", row_number().over(window)) \\\n",
    "        .filter(col(\"row_number\") <= n) \\\n",
    "        .drop(col(\"row_number\")) \n",
    "    #Result:\n",
    "    #+------+-------+-----+\n",
    "    #|userId|trackId|count|\n",
    "    #+------+-------+-----+\n",
    "    #|185109| 837238|    5|\n",
    "    #|185109| 870292|    4|\n",
    "    #|185109| 846624|    3|\n",
    "    #|185109| 961308|    3|\n",
    "    #|185109| 858070|    3|\n",
    "    #|185109| 858904|    3|\n",
    "    #|185109| 871513|    2|\n",
    "    #|185109| 839387|    2|\n",
    "    #|185109| 899991|    1|\n",
    "    #|185109| 936124|    1|\n",
    "    #+------+-------+-----+\n",
    "\n",
    "\n",
    "    #Sum all count (count of all tracks) for each UserId.\n",
    "    #key1 = \"userId\"; field = \"count\"\n",
    "    tmpDF = topsDF.groupBy(col(key1)).agg(col(key1), sum(col(field)).alias(\"sum_\" + field))\n",
    "    #Result:\n",
    "    #+------+------+---------+\n",
    "    #|userId|userId|sum_count|\n",
    "    #+------+------+---------+\n",
    "    #|185109|185109|       27|\n",
    "    #+------+------+---------+\n",
    "\n",
    "    #Normalize tracks for each user\n",
    "    normalizedDF = topsDF.join(tmpDF, key1, \"inner\") \\\n",
    "        .withColumn(\"norm_\" + field, col(field) / col(\"sum_\" + field)) \\\n",
    "        .cache()\n",
    "    #Result:\n",
    "    #+------+-------+-----+---------+--------------------+\n",
    "    #|userId|trackId|count|sum_count|          norm_count|\n",
    "    #+------+-------+-----+---------+--------------------+\n",
    "    #|185109| 837238|    5|       27| 0.18518518518518517|\n",
    "    #|185109| 870292|    4|       27| 0.14814814814814814|\n",
    "    #|185109| 846624|    3|       27|  0.1111111111111111|\n",
    "    #|185109| 961308|    3|       27|  0.1111111111111111|\n",
    "    #|185109| 858070|    3|       27|  0.1111111111111111|\n",
    "    #|185109| 858904|    3|       27|  0.1111111111111111|\n",
    "    #|185109| 871513|    2|       27| 0.07407407407407407|\n",
    "    #|185109| 839387|    2|       27| 0.07407407407407407|\n",
    "    #|185109| 899991|    1|       27|0.037037037037037035|\n",
    "    #|185109| 936124|    1|       27|0.037037037037037035|\n",
    "    #+------+-------+-----+---------+--------------------+\n",
    "    \n",
    "    return normalizedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, rank\n",
    "\n",
    "#Count rows grouping by userId and trackId\n",
    "userTrack = data.groupBy(col(\"userId\"), col(\"trackId\")).count();\n",
    "#Result: \n",
    "#+------+-------+-----+\n",
    "#|userId|trackId|count|\n",
    "#+------+-------+-----+\n",
    "#|185109| 870292|    4|\n",
    "\n",
    "userTrackNorm = norm(userTrack, \"userId\", \"trackId\", \"count\", 1000) \\\n",
    "        .withColumn(\"id\", col(\"userId\")) \\\n",
    "        .withColumn(\"id2\", col(\"trackId\")) \\\n",
    "        .withColumn(\"norm_count\", col(\"norm_count\") * 0.5) \\\n",
    "        .select(col(\"id\"), col(\"id2\"), col(\"norm_count\"));\n",
    "#Result: id - userId, id2 - trackId\n",
    "#+------+------+--------------------+\n",
    "#|    id|   id2|          norm_count|\n",
    "#+------+------+--------------------+\n",
    "#|185109|837238| 0.09259259259259259|\n",
    "#|185109|870292| 0.07407407407407407|\n",
    "#|185109|846624| 0.05555555555555555|\n",
    "#|185109|961308| 0.05555555555555555|\n",
    "#|185109|858070| 0.05555555555555555|\n",
    "#|185109|858904| 0.05555555555555555|\n",
    "#|185109|871513|0.037037037037037035|\n",
    "#|185109|839387|0.037037037037037035|\n",
    "#|185109|899991|0.018518518518518517|\n",
    "#|185109|936124|0.018518518518518517|\n",
    "#+------+------+--------------------+\n",
    "\n",
    "#The most popular track for each user\n",
    "window = Window.orderBy(col(\"norm_count\"));\n",
    "\n",
    "userTrackList = userTrackNorm.withColumn(\"position\", rank().over(window))\\\n",
    "    .filter(col(\"position\") < 50)\\\n",
    "    .orderBy(col(\"id\"), col(\"id2\"))\\\n",
    "    .select(col(\"id\"), col(\"id2\"))\\\n",
    "    .take(40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415763 853951\n",
      "436158 889948\n",
      "586043 800288\n",
      "586043 800317\n",
      "586043 801522\n",
      "586043 804741\n",
      "586043 805880\n",
      "586043 806233\n",
      "586043 806439\n",
      "586043 807873\n",
      "586043 808328\n",
      "586043 810571\n",
      "586043 811212\n",
      "586043 811848\n",
      "586043 815635\n",
      "586043 818116\n",
      "586043 819591\n",
      "586043 821062\n",
      "586043 822375\n",
      "586043 825775\n",
      "586043 825997\n",
      "586043 826725\n",
      "586043 831955\n",
      "586043 833018\n",
      "586043 834780\n",
      "586043 834887\n",
      "586043 835312\n",
      "586043 837744\n",
      "586043 838944\n",
      "586043 842614\n",
      "586043 844606\n",
      "586043 851992\n",
      "586043 852304\n",
      "586043 852734\n",
      "586043 852863\n",
      "586043 855577\n",
      "586043 856643\n",
      "586043 858618\n",
      "586043 858992\n",
      "586043 860220\n"
     ]
    }
   ],
   "source": [
    "for val in userTrackList:\n",
    "    print \"%s %s\" % val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
