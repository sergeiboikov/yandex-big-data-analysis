{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive Assignment 2. DML: Find Most Popular Tags\n",
    "\n",
    "Compare most popular tags in year 2016 with tags in 2009. Tag popularity is the number of questions (post_type_id=1) with this tag. Output top 10 tags in format:\n",
    "\n",
    "`tag <tab> rank in 2016 <tab> rank in 2009 <tab> tag popularity in 2016 <tab> tag popularity in 2009`\n",
    "    \n",
    "Example:\n",
    "\n",
    "`php 5 3 1234 5678`\n",
    "\n",
    "For 'rank' in each year use rank() function. Order by 'rank in 2016'.\n",
    "\n",
    "The part of the result on the sample dataset:\n",
    "\n",
    "`...\n",
    "android 3   52  1809    25\n",
    "php 4   3   1673    215\n",
    "python  5   11  1585    108\n",
    "c#  6   1   1519    423\n",
    "...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;\n",
    "USE stackoverflow_;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a query.hql\n",
    "select t.tag,\n",
    "       rank() over(order by t.q_2016 desc) as rank_2016,\n",
    "       rank() over(order by t.q_2009 desc) as rank_2009,\n",
    "       t.q_2016,\n",
    "       t.q_2009\n",
    "from (select tag, \n",
    "             sum(if(year = 2009, 1, 0)) as q_2009,\n",
    "             sum(if(year = 2016, 1, 0)) as q_2016\n",
    "      from stackoverflow_.posts LATERAL VIEW explode(tags) tagsTable as tag\n",
    "      where post_type_id=1\n",
    "        and year in (2009, 2016)\n",
    "      group by tag) t\n",
    "order by rank_2016\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar]\n",
      "OK\n",
      "Time taken: 0.398 seconds\n",
      "Query ID = jovyan_20200918065151_e1f1efaf-a332-4cc5-8736-f902aa4c4cb2\n",
      "Total jobs = 4\n",
      "Launching Job 1 out of 4\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1600405118633_0014, Tracking URL = http://867ad0b9430a:8088/proxy/application_1600405118633_0014/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1600405118633_0014\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2020-09-18 06:51:54,195 Stage-1 map = 0%,  reduce = 0%\n",
      "2020-09-18 06:52:00,461 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.52 sec\n",
      "2020-09-18 06:52:06,662 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.06 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 60 msec\n",
      "Ended Job = job_1600405118633_0014\n",
      "Launching Job 2 out of 4\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1600405118633_0015, Tracking URL = http://867ad0b9430a:8088/proxy/application_1600405118633_0015/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1600405118633_0015\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2020-09-18 06:52:17,786 Stage-2 map = 0%,  reduce = 0%\n",
      "2020-09-18 06:52:21,957 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.93 sec\n",
      "2020-09-18 06:52:28,171 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.3 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 300 msec\n",
      "Ended Job = job_1600405118633_0015\n",
      "Launching Job 3 out of 4\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1600405118633_0016, Tracking URL = http://867ad0b9430a:8088/proxy/application_1600405118633_0016/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1600405118633_0016\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2020-09-18 06:52:40,002 Stage-3 map = 0%,  reduce = 0%\n",
      "2020-09-18 06:52:44,240 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.14 sec\n",
      "2020-09-18 06:52:49,415 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 2.56 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 560 msec\n",
      "Ended Job = job_1600405118633_0016\n",
      "Launching Job 4 out of 4\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1600405118633_0017, Tracking URL = http://867ad0b9430a:8088/proxy/application_1600405118633_0017/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1600405118633_0017\n",
      "Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1\n",
      "2020-09-18 06:53:01,332 Stage-4 map = 0%,  reduce = 0%\n",
      "2020-09-18 06:53:05,555 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 0.99 sec\n",
      "2020-09-18 06:53:10,709 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 1.97 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 970 msec\n",
      "Ended Job = job_1600405118633_0017\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.06 sec   HDFS Read: 970861 HDFS Write: 316407 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.3 sec   HDFS Read: 322326 HDFS Write: 347254 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 2.56 sec   HDFS Read: 353629 HDFS Write: 378100 SUCCESS\n",
      "Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 1.97 sec   HDFS Read: 383274 HDFS Write: 188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 10 seconds 890 msec\n",
      "OK\n",
      "javascript\t1\t5\t2771\t192\n",
      "java\t2\t2\t2033\t243\n",
      "android\t3\t52\t1809\t25\n",
      "php\t4\t3\t1673\t215\n",
      "python\t5\t11\t1585\t108\n",
      "c#\t6\t1\t1519\t423\n",
      "html\t7\t14\t1212\t84\n",
      "jquery\t8\t8\t1167\t141\n",
      "ios\t9\t186\t914\t7\n",
      "css\t10\t20\t801\t59\n",
      "Time taken: 85.158 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "!hive -f query.hql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
