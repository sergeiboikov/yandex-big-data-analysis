{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive Assignment 3. DML: Calculate Amount of Posts per User Age\n",
    "\n",
    "Use Hive to complete the following task. Input tables was described in Hive Task1 and Hive Task2.\n",
    "\n",
    "Calculate number of questions and answers depending on users' age. Use Ð°ge from 'users' table, filter out users if their age is undefined. Output format:\n",
    "\n",
    "`age <tab> number of questions <tab> number of answers`\n",
    "    \n",
    "Example:\n",
    "\n",
    "`22 12345 5678`\n",
    "\n",
    "Output all ages. Order by age, increment.\n",
    "\n",
    "The part of the result on the sample dataset:\n",
    "\n",
    "`...\n",
    "21  11  24\n",
    "22  6   18\n",
    "23  12  15\n",
    "24  16  27\n",
    "25  20  33\n",
    "...`\n",
    "\n",
    "**Hint.** To simplify your code and reduce the quantity of MapReduce jobs produced by the query, use IF clause.\n",
    "\n",
    "Please use the tables 'posts' and 'users' from the database 'stackoverflow_'. 'Posts' is partitioned by year and by month, columns correspond to the fields of the lines described above:\n",
    "\n",
    "- id INT\n",
    "- post_type_id TINYINT (1 or 2) - 1 for questions, 2 for answers\n",
    "- date STRING\n",
    "- owner_user_id INT\n",
    "- parent_id INT\n",
    "- score INT\n",
    "- favorite_count INT\n",
    "- tags ARRAY<STRING>\n",
    "- year STRING (partition)\n",
    "- month STRING (partition)\n",
    "\n",
    "'Users' contains the following columns:\n",
    "\n",
    "- id INT\n",
    "- reputation INT\n",
    "- creation_date STRING\n",
    "- display_name STRING\n",
    "- location STRING\n",
    "- age INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;\n",
    "\n",
    "USE stackoverflow_;\n",
    "select u.age,\n",
    "       sum(if(post_type_id = 1, 1, 0)) as questions_sum,\n",
    "       sum(if(post_type_id = 2, 1, 0)) as answers_sum\n",
    "from Users u\n",
    "inner join Posts p on p.owner_user_id = u.id\n",
    "group by age\n",
    "order by age;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar]\n",
      "OK\n",
      "Time taken: 0.357 seconds\n",
      "Query ID = jovyan_20200910090101_41e0829c-3994-4427-83f7-af43a83ddc78\n",
      "Total jobs = 2\n",
      "Execution log at: /tmp/jovyan/jovyan_20200910090101_41e0829c-3994-4427-83f7-af43a83ddc78.log\n",
      "2020-09-10 09:01:13\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2020-09-10 09:01:14\tDump the side-table for tag: 0 with group count: 64208 into file: file:/tmp/jovyan/a1256d15-2030-47eb-a616-97b1d478f32c/hive_2020-09-10_09-01-09_132_5962586329884254596-1/-local-10005/HashTable-Stage-2/MapJoin-mapfile00--.hashtable\n",
      "2020-09-10 09:01:14\tUploaded 1 File to: file:/tmp/jovyan/a1256d15-2030-47eb-a616-97b1d478f32c/hive_2020-09-10_09-01-09_132_5962586329884254596-1/-local-10005/HashTable-Stage-2/MapJoin-mapfile00--.hashtable (1425472 bytes)\n",
      "2020-09-10 09:01:14\tEnd of local task; Time Taken: 0.884 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1599716343617_0010, Tracking URL = http://33f85178d43a:8088/proxy/application_1599716343617_0010/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1599716343617_0010\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2020-09-10 09:01:22,378 Stage-2 map = 0%,  reduce = 0%\n",
      "2020-09-10 09:01:29,703 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.68 sec\n",
      "2020-09-10 09:01:34,923 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 3.75 sec\n",
      "MapReduce Total cumulative CPU time: 3 seconds 750 msec\n",
      "Ended Job = job_1599716343617_0010\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1599716343617_0011, Tracking URL = http://33f85178d43a:8088/proxy/application_1599716343617_0011/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1599716343617_0011\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2020-09-10 09:01:45,686 Stage-3 map = 0%,  reduce = 0%\n",
      "2020-09-10 09:01:49,831 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.64 sec\n",
      "2020-09-10 09:01:56,010 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 1.68 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 680 msec\n",
      "Ended Job = job_1599716343617_0011\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 3.75 sec   HDFS Read: 2259950 HDFS Write: 1079 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 1.68 sec   HDFS Read: 5662 HDFS Write: 387 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 430 msec\n",
      "OK\n",
      "NULL\t934\t846\n",
      "14\t1\t0\n",
      "15\t1\t2\n",
      "16\t2\t0\n",
      "17\t0\t1\n",
      "18\t4\t1\n",
      "19\t1\t1\n",
      "20\t0\t2\n",
      "21\t11\t24\n",
      "22\t6\t18\n",
      "23\t12\t15\n",
      "24\t16\t27\n",
      "25\t20\t33\n",
      "26\t23\t44\n",
      "27\t28\t56\n",
      "28\t24\t37\n",
      "29\t24\t66\n",
      "30\t26\t67\n",
      "31\t17\t33\n",
      "32\t13\t48\n",
      "33\t11\t40\n",
      "34\t24\t36\n",
      "35\t12\t42\n",
      "36\t8\t64\n",
      "37\t9\t35\n",
      "38\t6\t17\n",
      "39\t3\t7\n",
      "40\t1\t13\n",
      "41\t5\t20\n",
      "42\t5\t22\n",
      "43\t2\t26\n",
      "44\t7\t35\n",
      "45\t1\t4\n",
      "46\t7\t9\n",
      "47\t1\t1\n",
      "48\t1\t1\n",
      "49\t1\t26\n",
      "50\t1\t26\n",
      "51\t4\t5\n",
      "52\t0\t2\n",
      "53\t0\t2\n",
      "54\t0\t1\n",
      "57\t0\t3\n",
      "58\t1\t57\n",
      "60\t0\t6\n",
      "61\t0\t3\n",
      "64\t2\t1\n",
      "86\t0\t1\n",
      "96\t3\t1\n",
      "Time taken: 47.965 seconds, Fetched: 49 row(s)\n"
     ]
    }
   ],
   "source": [
    "!hive -f query.hql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
